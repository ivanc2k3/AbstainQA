{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T07:17:07.016938Z",
     "iopub.status.busy": "2025-11-30T07:17:07.016610Z",
     "iopub.status.idle": "2025-11-30T07:26:42.734376Z",
     "shell.execute_reply": "2025-11-30T07:26:42.733547Z",
     "shell.execute_reply.started": "2025-11-30T07:17:07.016914Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading LLM: mistralai/Mistral-7B-v0.1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2f9453e3fd418d8d8ca4b4e16ff88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b19e44ab85c4f118d0cc51042d36bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911353b7f0ed4c24b85600e544ed1b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64530309bbf24e1189648fef2258e43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6ca6ae39624480bb7382cdbf44dff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-11-30 07:17:19.299056: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764487039.710646      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764487039.834317      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90ca91f09f14553b602e63f84864875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0b38009b274453b17a3aa072504233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76fbc16c410473796e2c92dcf900461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9cba91e9774bb2b74027410a5901f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efd6ff7da35475092649c8739fa93a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a18e7cd246a438cae99db57c5740474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨å¾ž Dev (Train) æå–ç‰¹å¾µ (Paper Baseline Method)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [03:50<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨å¾ž Test (Eval) æå–ç‰¹å¾µ (Paper Baseline Method)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [03:57<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "é–‹å§‹è¨“ç·´ Paper Baseline Probe...\n",
      "Epoch 10 | Loss: 0.1257\n",
      "\n",
      "==============================\n",
      "ðŸ† è«–æ–‡åŸºæº–ç·šé‡ç¾çµæžœ (Paper Reproduction)\n",
      "==============================\n",
      "ç¸½æ¨£æœ¬æ•¸: 1000\n",
      "Counts: A=470, B=134, C=235, D=161\n",
      "------------------------------\n",
      "1. Reliable Accuracy (R-Acc) : 0.6667\n",
      "2. Effective Reliability (ER): 0.2350\n",
      "3. Abstain Accuracy (A-Acc)  : 0.6310\n",
      "4. Abstain F1 Score (A-F1)   : 0.4660\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Unknown (0)       0.55      0.41      0.47       396\n",
      "   Known (1)       0.67      0.78      0.72       604\n",
      "\n",
      "    accuracy                           0.63      1000\n",
      "   macro avg       0.61      0.59      0.59      1000\n",
      "weighted avg       0.62      0.63      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. è¨­å®šåƒæ•¸\n",
    "# ==========================================\n",
    "JSON_FILE = \"/kaggle/input/knowledge/mmlu.json\"\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ==========================================\n",
    "# 2. å®šç¾©è«–æ–‡åŽŸç‰ˆ Probe (LinearModel)\n",
    "# ==========================================\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, input_dim)\n",
    "        self.out = nn.Linear(input_dim, 2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.out(self.activation(self.linear(x)))\n",
    "\n",
    "# ==========================================\n",
    "# 3. è¼”åŠ©å‡½æ•¸\n",
    "# ==========================================\n",
    "def format_json_prompt(item):\n",
    "    prompt = f\"Question: {item['question']}\\n\"\n",
    "    for key in ['A', 'B', 'C', 'D']:\n",
    "        choice_text = item['choices'].get(key, \"\")\n",
    "        prompt += f\"{key}. {choice_text}\\n\"\n",
    "    prompt += \"Answer:\"\n",
    "    return prompt\n",
    "\n",
    "def compute_paper_metrics(correct_flags, abstain_flags):\n",
    "    A = 0; B = 0; C = 0; D = 0\n",
    "    for i in range(len(correct_flags)):\n",
    "        if abstain_flags[i] == 1: \n",
    "            if correct_flags[i] == 1: B += 1\n",
    "            else: D += 1\n",
    "        else: \n",
    "            if correct_flags[i] == 1: A += 1\n",
    "            else: C += 1\n",
    "    \n",
    "    total = A + B + C + D\n",
    "    r_acc = A / (A + C) if (A + C) > 0 else 0.0\n",
    "    er = (A - C) / total\n",
    "    a_acc = (A + D) / total\n",
    "    \n",
    "    precision = D / (B + D) if (B + D) > 0 else 0.0\n",
    "    recall = D / (C + D) if (C + D) > 0 else 0.0\n",
    "    a_f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return r_acc, er, a_acc, a_f1, A, B, C, D\n",
    "\n",
    "# ==========================================\n",
    "# 4. æå–ç‰¹å¾µ\n",
    "# ==========================================\n",
    "def extract_features_baseline(data_list, model, tokenizer, desc=\"Processing\"):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"æ­£åœ¨å¾ž {desc} æå–ç‰¹å¾µ (Paper Baseline Method)...\")\n",
    "    \n",
    "    for item in tqdm(data_list):\n",
    "        prompt = format_json_prompt(item)\n",
    "        ground_truth = item['answer'].strip().upper()\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 1. æå– Hidden States\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            \n",
    "            # === é—œéµå·®ç•° 1: åªå–æœ€å¾Œä¸€å±¤ ===\n",
    "            last_hidden_state = outputs.hidden_states[-1] # [1, seq_len, 4096]\n",
    "            \n",
    "            # === é—œéµå·®ç•° 2: Mean Pooling (å¹³å‡æ± åŒ–) ===\n",
    "            mean_pooled = last_hidden_state.mean(dim=1) # [1, 4096]\n",
    "            \n",
    "            # è½‰åž‹\n",
    "            feature_vector = mean_pooled.to(dtype=torch.float32)\n",
    "            \n",
    "            # 2. ç”Ÿæˆç­”æ¡ˆ\n",
    "            generated_ids = model.generate(\n",
    "                **inputs, \n",
    "                max_new_tokens=1, \n",
    "                do_sample=False, # é€™è£¡è®“ä»–å›ºå®šç”Ÿæˆæœ€é«˜æ©ŸçŽ‡çš„token\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "            new_token_id = generated_ids[0][-1]\n",
    "            pred_text = tokenizer.decode(new_token_id).strip().upper()\n",
    "            \n",
    "            # 3. æ¨™è¨»\n",
    "            label = 1.0 if pred_text == ground_truth else 0.0\n",
    "            \n",
    "            features.append(feature_vector)\n",
    "            labels.append(label)\n",
    "            \n",
    "    X = torch.cat(features, dim=0)\n",
    "    y = torch.tensor(labels).long()\n",
    "    return X, y\n",
    "\n",
    "# ==========================================\n",
    "# 5. ä¸»ç¨‹å¼\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    \n",
    "    if not os.path.exists(JSON_FILE): return\n",
    "    with open(JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "        raw_data = json.load(f)\n",
    "    \n",
    "    # è¼‰å…¥æ¨¡åž‹\n",
    "    print(f\"Loading LLM: {MODEL_NAME}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token\n",
    "    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "    model.eval()\n",
    "    \n",
    "    # æå–ç‰¹å¾µ (Baseline æ–¹å¼)\n",
    "    X_train, y_train = extract_features_baseline(raw_data['dev'], model, tokenizer, desc=\"Dev (Train)\")\n",
    "    X_test, y_test = extract_features_baseline(raw_data['test'], model, tokenizer, desc=\"Test (Eval)\")\n",
    "    \n",
    "    # é‡‹æ”¾é¡¯å­˜\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # è¨“ç·´ Probe\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"é–‹å§‹è¨“ç·´ Paper Baseline Probe...\")\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train.to(DEVICE), y_train.to(DEVICE))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    input_dim = X_train.shape[1]\n",
    "    probe = LinearModel(input_dim).to(DEVICE)\n",
    "    optimizer = optim.Adam(probe.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss() # ç”¨ CrossEntropy å› ç‚ºæ˜¯ 2 å€‹ logits\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        probe.train()\n",
    "        epoch_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = probe(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "             print(f\"Epoch {epoch+1:02d} | Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # è©•ä¼°\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"ðŸ† è«–æ–‡åŸºæº–ç·šé‡ç¾çµæžœ (Paper Reproduction)\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    probe.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = probe(X_test.to(DEVICE))\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        \n",
    "    # å–å‡º \"Known\" (Label 1) çš„æ©ŸçŽ‡\n",
    "    prob_known = probs[:, 1]\n",
    "    \n",
    "    threshold = 0.5\n",
    "    final_preds = (prob_known > threshold).astype(int)\n",
    "    \n",
    "    paper_correct_flags = y_test.numpy().astype(int)\n",
    "    paper_abstain_flags = 1 - final_preds\n",
    "    \n",
    "    r_acc, er, a_acc, a_f1, A, B, C, D = compute_paper_metrics(paper_correct_flags, paper_abstain_flags)\n",
    "    \n",
    "    print(f\"ç¸½æ¨£æœ¬æ•¸: {len(y_test)}\")\n",
    "    print(f\"Counts: A={A}, B={B}, C={C}, D={D}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"1. Reliable Accuracy (R-Acc) : {r_acc:.4f}\")\n",
    "    print(f\"2. Effective Reliability (ER): {er:.4f}\")\n",
    "    print(f\"3. Abstain Accuracy (A-Acc)  : {a_acc:.4f}\")\n",
    "    print(f\"4. Abstain F1 Score (A-F1)   : {a_f1:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(classification_report(paper_correct_flags, final_preds, target_names=[\"Unknown (0)\", \"Known (1)\"]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8874382,
     "sourceId": 13926324,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
